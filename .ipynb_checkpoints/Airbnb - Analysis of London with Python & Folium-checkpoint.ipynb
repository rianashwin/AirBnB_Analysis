{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and acknowledgements\n",
    "\n",
    "This notebook will take a look at Airbnb listings in London. I spent three exciting years here while completing my undergrad at the London School of Economics. London holds many fond memories for me!\n",
    "\n",
    "We will focus on visualisations, using some new techniques of data & analysis that I've learnt on the job. First, we shall perform discovery and analysis on jupyter. Next, we deploy this in a dashboard using Bokeh!\n",
    "\n",
    "We also aspire to make this into a decision-support tool. Therefore, we shall attempt to provide insights for both tourists as well as Airbnb itself. To do:\n",
    "- illegal outlets\n",
    "- growth rates\n",
    "- professionalisation / monopolisation of listings (hosts have more than 1 listing)\n",
    "- price of multihosts vs single hosts\n",
    "- associated texts for multi vs single\n",
    "- renting out of entire property?\n",
    "- rates per neighbourhood\n",
    "- rates per review\n",
    "- metric for best place (w-ave of rates, reviews, vicinity to landmarks)\n",
    "- safety?\n",
    "- what affects review scores?\n",
    "- different scores by different host types?\n",
    "- bookings seasons: availability and price rate by date? price by neighbourhood? \n",
    "\n",
    "I've always enjoyed visualising data, and building things that users can interact with. Hope you find this useful!\n",
    "\n",
    "Acknowledgements:\n",
    "- https://www.kaggle.com/erikbruin/airbnb-the-amsterdam-story-with-interactive-maps [was inspired by this notebook, thank you for the amazing work you do Erik Bruinn!]\n",
    "- https://github.com/rweng18/bokeh_map\n",
    "\n",
    "Data source: http://insideairbnb.com/london/\n",
    "\n",
    "Relevant articles:\n",
    "- https://qz.com/876984/airbnb-is-gradually-losing-one-of-its-biggest-advantages-over-hotels/\n",
    "- https://www.wired.co.uk/article/airbnb-growth-london-housing-data-insideairbnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7065765c3f6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import folium\n",
    "from folium.plugins import FastMarkerCluster # technique learnt from Erik Bruin\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) #set full rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data_path = \"../input/airbnb/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for datafile in os.listdir(raw_data_path):\n",
    "    print(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptions of data (from https://www.kaggle.com/erikbruin/airbnb-the-amsterdam-story-with-interactive-maps)\n",
    "\n",
    "- *calendar.csv.gz*: The calendar has 365 records for each listing. It specifies the whether the listing is available on a particular day (365 days ahead), and the price on that day.\n",
    "- *listings_summary.csv*: A listing is basically an advertisement. This file holds the most useful variables that can be used visualizations.\n",
    "- *listings.csv*: This file holds the same variables as the listing file plus 80 additional variables.\n",
    "- *neighbourhoods.csx*: Simple file with the names of the neighbouhoods\n",
    "- *reviews_summary.csv*: This is a simple file that can be used to count the number of reviews by listing (for a specific period). We don't load this data.\n",
    "- *reviews.csv: This file holds the full details of all reviews, and can also be used for instance for text mining.\n",
    "- *neighbourhoods.geojson*: This is the shape file that can be used in conjunction with interactive maps (such as Leaflet for R of the Python folium package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings = pd.read_csv(raw_data_path + \"listings_summary.csv\")\n",
    "df_listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_listings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_listings_details = pd.read_csv(raw_data_path + 'listings.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_listings_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_listings_details.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_details = pd.read_csv(raw_data_path + 'reviews.csv')\n",
    "print(df_reviews_details.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_details.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = pd.read_csv(raw_data_path + 'calendar.csv')\n",
    "print(df_calendar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1) Exploratory analysis - listings\n",
    "\n",
    "In this section, we will study the various columns in our listing dataset. Before that, we will do some cleanup and joins to enrich our data.\n",
    "\n",
    "## 2.X Join listings with listing_details, to enrich our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_listings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_listings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_listings_details.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on reference notebook, as well as inspecting the full listings sheet, we can consider bringing these columns in to our main listings sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_to_pull = [\"id\",\"property_type\", \"accommodates\", \"first_review\", \"review_scores_value\", \n",
    "                \"review_scores_cleanliness\", \"review_scores_location\", \"review_scores_accuracy\", \n",
    "                \"review_scores_communication\", \"review_scores_checkin\", \"review_scores_rating\", \n",
    "                \"maximum_nights\", \"listing_url\", \n",
    "                \"host_is_superhost\", \"host_about\", \"host_response_time\", \"host_response_rate\", \n",
    "                \"street\", \"price\", \"weekly_price\", \"monthly_price\", \"market\",\n",
    "                \"host_identity_verified\",\"neighbourhood_cleansed\", \"bathrooms\", \"bedrooms\", \"beds\", \"bed_type\",\n",
    "                \"experiences_offered\",\"notes\",\"neighborhood_overview\", \"amenities\", \"cleaning_fee\",\n",
    "                \"cancellation_policy\",\"square_feet\"\n",
    "               ]\n",
    "\n",
    "df_listings = pd.merge(df_listings, df_listings_details[cols_to_pull], left_on='id', right_on='id', how='left')\n",
    "df_listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "del df_listings_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.X Missing values and duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_listings.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, weekly_price, square_feet and monthly_price are mainly missing. We can drop these. We will also drop neighbourhood_group because it seems to be entirely missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_listings.drop(['weekly_price','monthly_price','neighbourhood_group'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_listings[df_listings[\"neighbourhood\"]!=df_listings[\"neighbourhood_cleansed\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see that \"neighbourhood\" is the same as \"neighbourhood_cleansed\". Let's drop neighbourhood_cleansed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_listings.drop(['neighbourhood_cleansed'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also note that both the summarised listing sheet and the detailed listings sheet has a column for \"price\" Are these the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_listings[[\"price_x\",\"price_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_listings[\"price_y\"] = df_listings[\"price_y\"].str.replace(\",\",\"\")\n",
    "df_listings[\"price_y\"] = df_listings[\"price_y\"].str.replace(\"$\",\"\")\n",
    "df_listings[\"price_y\"] = df_listings[\"price_y\"].astype(float)\n",
    "df_listings[df_listings[\"price_x\"]!=df_listings[\"price_y\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can conclude the that price in the listing details list is weekly to the price in the trimmed listings list. We can also assume cleaning fees is over and above price. (Let's also rename the column to make it more intuitive.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_listings.drop([\"price_y\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_listings = df_listings.rename(columns={\"price_x\":\"price_per_night\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_listings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Name of listing\n",
    "\n",
    "\n",
    "This seems more like a description of the listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings['name'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a number of listings have the same description / name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df_listings[df_listings.groupby('name')['name'].transform('size') > 1].sort_values(\"name\")\n",
    "print(\"Number of descriptions with more than one listing: \",len(temp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note however that all these potential \"duplicate\" listings have more than one host_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of descriptions with more than one listing, and more than one host id:\",len(temp_df[temp_df.groupby('name')['host_id'].transform('size') > 1].sort_values(\"name\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I doubt these are duplicate listings. The more likely scenario is that property owners are refering to the descriptions of other properties within their vicinities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Neighbourhood\n",
    "\n",
    "We see that Westminster is the most popular area. This is pretty much central London, and is bound to attract the most crowds. The map following the graph further illustrates this point. Feel free to interact with the map - zoom in/out to get a better understanding of the distribution of listings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings['neighbourhood'].value_counts(ascending=True).plot(kind='barh', figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "london_centre_coords = [51.507515, -0.127802]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "these_lats = df_listings['latitude'].tolist()\n",
    "these_lons = df_listings['longitude'].tolist()\n",
    "these_lat_lons = list(zip(these_lats, these_lons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "this_map_neighbourhood_1 = folium.Map(location=london_centre_coords,zoom_start=10.5)\n",
    "    \n",
    "FastMarkerCluster(data=these_lat_lons).add_to(this_map_neighbourhood_1) # this is a lot faster than the code above. Technique from Erik Bruin\n",
    "\n",
    "this_map_neighbourhood_1\n",
    "# this_map_neighbourhood_1.save('index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Room type\n",
    "\n",
    "Entire homes or apartments are the most popular room_types. There also appear to be some fairly expensive hotel rooms and private rooms. We will look at prices in a separate section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.room_type.value_counts().plot.pie(y='room_type', figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(x=\"price_per_night\", y=\"room_type\", data=df_listings) #, showfliers=False) #uncomment if want to hide outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Property type\n",
    "\n",
    "There are a lot more property types compared to room types. We likely won't use this feature in later analyses but worth inspecting now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.property_type.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.property_type.value_counts().plot.pie(y='property_type', figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Price per night\n",
    "\n",
    "Let's study the price rates by room rates (we'll look at price against other dimensions such as neighbourhood in later sections of this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(x=\"price_per_night\", y=\"room_type\", data=df_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appear to be some outliers in prices. Let's remove these and look at the distributions again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(x=\"price_per_night\", y=\"room_type\", data=df_listings, showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Number of reviews\n",
    "\n",
    "Typically, or at least for me, I tend to look closer at listings which have more reviews. It lends a certain sense of legitimacy to listings. Let's take a look at the top 10% of listings and see if their ratings are any different from the rest of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_quantiles = df_listings['number_of_reviews'].quantile([.1, .25, .5, .75, 0.9]).to_frame()\n",
    "temp_most_reviewed = df_listings[df_listings['number_of_reviews']>=review_quantiles[review_quantiles.index==0.9].values[0][0]].copy()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.distplot(temp_most_reviewed['review_scores_rating'],kde = True, label=\"Top 10% by review count\")\n",
    "sns.distplot(df_listings['review_scores_rating'],kde = True, label=\"Overall population in London\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite. What about their price? Not much difference compared to the plots in section 2.XX. Therefore, difficult to say whether the ratings or price differs much according to number of reviews. Probably not much more than my own hunch anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(x=\"price_per_night\", y=\"room_type\", data=temp_most_reviewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also noticed there are a few listings which have had more than 600 reviews. They look to have been around for some time based on the 'first_review' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings['days_since_first_review'] = pd.to_datetime(df_listings['first_review'], format='%Y-%m-%d') # https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "df_listings['days_since_first_review'] = round((pd.to_datetime(\"now\") - df_listings['days_since_first_review']) /np.timedelta64(1,'D'))\n",
    "df_listings[df_listings['number_of_reviews']>=600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_quantiles = df_listings['number_of_reviews'].quantile([.1, .25, .5, .75, 0.9]).to_frame()\n",
    "temp_most_reviewed = df_listings[df_listings['number_of_reviews']>=review_quantiles[review_quantiles.index==0.9].values[0][0]].copy()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.distplot(temp_most_reviewed['days_since_first_review'],kde = True, label=\"Top 10% by review count\")\n",
    "sns.distplot(df_listings['days_since_first_review'],kde = True, label=\"Overall population in London\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, this confirms our hunch - number of reviews is largely driven by how long a property has been listed. This makes sense. What else can we do to look at popularity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Reviews per month\n",
    "\n",
    "What if we looked at the number of reviews per month. Perhaps this is a better measure of popularity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_quantiles = df_listings['reviews_per_month'].quantile([.1, .25, .5, .75, 0.9]).to_frame()\n",
    "temp_most_reviewed = df_listings[df_listings['reviews_per_month']>=review_quantiles[review_quantiles.index==0.9].values[0][0]].copy()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "sns.distplot(temp_most_reviewed['review_scores_rating'],kde = True, label=\"Top 10% by review count per month\")\n",
    "sns.distplot(df_listings['review_scores_rating'],kde = True, label=\"Overall population in London\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, ratings don't differ much but we can see that price per night actually is not quite what we've seen before. Perhaps then having more reviews per month matters. Why though? Perhaps it's a sign of people booking your listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(x=\"price_per_night\", y=\"room_type\", data=temp_most_reviewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note as well as that in the top 10 by review count, distribution by room type is slightly different - private rooms are more popular than 'entire home/apt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_most_reviewed.room_type.value_counts().plot.pie(y='room_type', figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp_most_reviewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Accomodates\n",
    "\n",
    "Nothing much to say here. Some private rooms can accomodate quite a number of people. Shame the 'square_feet' column is not usable (too many missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(x=\"accommodates\", y=\"room_type\", data=df_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Superhost\n",
    "\n",
    "https://www.airbnb.com/help/article/829/how-do-i-become-a-superhost\n",
    "\n",
    "\"How do I become a Superhost?\n",
    "To become a Superhost, you need to have an account in good standing and meet the following requirements. Your performance is measured over your previous 12 months of hosting. However, you do not need to have hosted for the full 12 months to qualify. Check your Superhost status.\n",
    "\n",
    "Superhost requirements\n",
    "Completed at least 10 trips OR completed 3 reservations that total at least 100 nights\n",
    "Maintained a 90% response rate or higher\n",
    "Maintained a 1% percent cancellation rate (1 cancellation per 100 reservations) or lower, with exceptions made for those that fall under our Extenuating Circumstances policy\n",
    "Maintained a 4.8 overall rating (this rating looks at the past 365 days of reviews, based on the date the guest left a review, not the date the guest checked out)\n",
    "Earning Superhost status\n",
    "You don’t need to apply to become a Superhost. If you meet the program requirements on the quarterly assessment date, you'll qualify for Superhost status. Quarterly assessments begin on January 1st, April 1st, July 1st, and October 1st, every year. We’ll notify you of your Superhost status at the end of each assessment period—which usually finishes 5 days after the assessment begins. Only primary hosts are eligible to attain Superhost status.\"\n",
    "\n",
    "\n",
    "Majority are not superhosts - this is good. It dilutes the value of 'superhost' if there are too many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings['host_is_superhost'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings['host_response_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings['host_response_rate'] = df_listings['host_response_rate'].str.replace(\"%\",\"\")\n",
    "df_listings['host_response_rate'] = df_listings['host_response_rate'].astype(\"float\")\n",
    "df_listings['host_response_rate'] = round(df_listings['host_response_rate']/10)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set_style('whitegrid')\n",
    "# avg_duration = df['duration'].mean()\n",
    "\n",
    "# lst = [df]\n",
    "# df[\"duration_status\"] = np.nan\n",
    "\n",
    "# for col in lst:\n",
    "#     col.loc[col[\"duration\"] < avg_duration, \"duration_status\"] = \"below_average\"\n",
    "#     col.loc[col[\"duration\"] > avg_duration, \"duration_status\"] = \"above_average\"\n",
    "    \n",
    "pct_term = pd.crosstab(df_listings['host_is_superhost'], df_listings['host_response_time']).apply(lambda r: round(r/r.sum(), 2) * 100, axis=1)\n",
    "\n",
    "\n",
    "ax = pct_term.plot(kind='bar', stacked=False, cmap='RdBu')\n",
    "plt.title(\"The Impact of Response Time \\n in Determining a Superhost Status\", fontsize=18)\n",
    "plt.xlabel(\"Superhost status\", fontsize=18);\n",
    "plt.ylabel(\"Percentage (%)\", fontsize=18)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.02, p.get_height() * 1.02))\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set_style('whitegrid')\n",
    "# avg_duration = df['duration'].mean()\n",
    "\n",
    "# lst = [df]\n",
    "# df[\"duration_status\"] = np.nan\n",
    "\n",
    "# for col in lst:\n",
    "#     col.loc[col[\"duration\"] < avg_duration, \"duration_status\"] = \"below_average\"\n",
    "#     col.loc[col[\"duration\"] > avg_duration, \"duration_status\"] = \"above_average\"\n",
    "    \n",
    "pct_term = pd.crosstab(df_listings['host_is_superhost'], df_listings['host_response_rate']).apply(lambda r: round(r/r.sum(), 2) * 100, axis=1)\n",
    "\n",
    "\n",
    "ax = pct_term.plot(kind='bar', stacked=False, cmap='RdBu')\n",
    "plt.title(\"The Impact of Response Rate \\n in Determining a Superhost Status\", fontsize=18)\n",
    "plt.xlabel(\"Superhost status\", fontsize=18);\n",
    "plt.ylabel(\"Percentage (%)\", fontsize=18)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.02, p.get_height() * 1.02))\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set_style('whitegrid')\n",
    "# avg_duration = df['duration'].mean()\n",
    "\n",
    "# lst = [df]\n",
    "# df[\"duration_status\"] = np.nan\n",
    "\n",
    "# for col in lst:\n",
    "#     col.loc[col[\"duration\"] < avg_duration, \"duration_status\"] = \"below_average\"\n",
    "#     col.loc[col[\"duration\"] > avg_duration, \"duration_status\"] = \"above_average\"\n",
    "    \n",
    "pct_term = pd.crosstab(df_listings['host_is_superhost'], df_listings['host_identity_verified']).apply(lambda r: round(r/r.sum(), 2) * 100, axis=1)\n",
    "\n",
    "\n",
    "ax = pct_term.plot(kind='bar', stacked=False, cmap='RdBu')\n",
    "plt.title(\"The Impact of Identity Verification \\n in Determining a Superhost Status\", fontsize=18)\n",
    "plt.xlabel(\"Superhost status\", fontsize=18);\n",
    "plt.ylabel(\"Percentage (%)\", fontsize=18)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.02, p.get_height() * 1.02))\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pct_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Bathrooms\n",
    "\n",
    "We see some properties have an unusual number of bathrooms. Firstly some have quite a few bathrooms! Some of these really do not make sense. For example, how does a hotel room have so many bathrooms. Or for that matter, how does a shared room work with so many bathrooms. Are these shared rooms or hotels actually dormitories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(x=\"bathrooms\", y=\"room_type\", data=df_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings[(df_listings['bathrooms']>=2.5) & (df_listings['room_type']=='Private room')]['property_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings[(df_listings['bathrooms']>=2.5) & (df_listings['room_type']=='Hotel room')]['property_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings[(df_listings['bathrooms']>=2.5) & (df_listings['room_type']=='Shared room')]['property_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not quite sure how could have half a bathroom. Can't really say what property type this belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df_listings[~(df_listings.isnull())]\n",
    "temp_df[(temp_df['bathrooms'] != df_listings['bathrooms']// 1)]['property_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Bedrooms and beds. Nothing untoward here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(x=\"bedrooms\", y=\"room_type\", data=df_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings['bedrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(x=\"beds\", y=\"room_type\", data=df_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Bed types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.bed_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Experiences offered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.experiences_offered.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Cancellation policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.cancellation_policy.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Amenities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_amenities = df_listings.amenities.value_counts().index.tolist()\n",
    "list_amenities = [re.sub('[\"\"\\{\\}]','',s) for s in list_amenities]\n",
    "\n",
    "unique_list = []\n",
    "for x in list_amenities:\n",
    "    unique_list.extend([y.upper().strip() for y in x.split(\",\") if y.upper().strip() not in unique_list])\n",
    "\n",
    "print(len(unique_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list.sort()\n",
    "unique_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appear to quite a number of different amenities. Let's see if the absolute basics are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.amenities = df_listings.amenities.str.strip()\n",
    "df_listings.amenities = df_listings.amenities.str.upper()\n",
    "df_listings.amenities = df_listings.amenities.str.replace('[\"\"\\{\\}]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings[\"INTERNET\"] = df_listings.apply(lambda row: 1 if any(t in row['amenities'] for t in [\"INTERNET\", \"WIFI\"]) else 0,axis=1)\n",
    "\n",
    "df_listings[\"WASHER_DRYER\"] = df_listings.apply(lambda row: 1 if any(t in row['amenities'] for t in [\"WASHER\", \"WASHER / DRYER\"]) else 0,axis=1)\n",
    "\n",
    "df_listings[\"TV\"] = df_listings.apply(lambda row: 1 if any(t in row['amenities'] for t in [\"CABLE TV\", \"APPLE TV\", \"HBO GO\", \"NETFLIX\", \"SMART TV\", \"TV\"]) else 0,axis=1)\n",
    "\n",
    "\n",
    "for amenity in  [\"BREAKFAST\", \"COOKING BASICS\", \"EN SUITE BATHROOM\", \"HEATING\", \"LOCKBOX\", \"HOT WATER\"]:\n",
    "    df_listings[amenity] = df_listings.apply(lambda row: 1 if amenity in row['amenities'] else 0,axis=1)\n",
    "    \n",
    "df_listings[[\"INTERNET\",\"BREAKFAST\", \"COOKING BASICS\", \"EN SUITE BATHROOM\", \"HEATING\", \"LOCKBOX\", \"WASHER_DRYER\", \"HOT WATER\", \"TV\"]].sum()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll study these in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.XX Cleaning fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.cleaning_fee = df_listings.cleaning_fee.str.replace('[$,]','')\n",
    "df_listings.cleaning_fee = df_listings.cleaning_fee.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings[\"cleaning_fee_to_price\"] = df_listings.cleaning_fee / df_listings.price_per_night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "ax = sns.boxplot(x=\"cleaning_fee_to_price\", data=df_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2) Exploratory analysis - calendar\n",
    "\n",
    "In this section, we will study the various columns in our calendar dataset. The calendar has 365 records for each listing. It specifies the whether the listing is available on a particular day (365 days ahead), and the price on that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_calendar.listing_id.value_counts().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.available.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't quite make sense of what the minimum and maximum nights represent. I won't be using these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_calendar.minimum_nights.min(), df_calendar.minimum_nights.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_calendar.maximum_nights.min(), df_calendar.maximum_nights.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar.drop([\"minimum_nights\",\"maximum_nights\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this file has availability from Nov 2019 to Nov 2020. In subsequent sections, we will analyse how availability changes over time during this period, as well as behaviour of prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_calendar.date.min(), df_calendar.date.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3) Exploratory analysis - reviews\n",
    "\n",
    "In this section, we will study the various columns in our reviews_details dataset. This file holds the full details of all reviews. Taking help from Erik Bruin's amazing notebook, we'll try to do some text mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_details.comments.fillna('', inplace=True)\n",
    "df_reviews_details.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it may be useful to match these with host details such as host name, whether they were a super host or not. We can contextualise the review comments with the overall review scores, and perhaps by geographical region. Perhaps reviews comments are harsher for central london because of prices? It would then make sense to compare review comments with the price per night. We'll tackle this in subsequent sectios.\n",
    "\n",
    "One thing to note though is we are not quite sure what date refers to - it likely refer to when the review was posted, not when the reviewer was staying at this property. We need to be mindful of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next section, we will attempt to build analytics that can help various parties. We will term them \"Decision Support Analytics\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Decision Support Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.X.X Can the data tell me what's different about listings which have low review scores vs those who have high review scores?\n",
    "\n",
    "Looks like most listings tend to have higher scores. There are a few on the lower end, but generally higher scores make sense - a listing is unlikely to survive very long if it has poor scores. Also, perhaps visitors aren't quite as keen to post negative reviews than they are to review positively. Something to ponder. \n",
    "\n",
    "As highlighted by Erik Bruin, here's an article that address this point about AirBnB reviews: https://mashable.com/2015/02/25/airbnb-reviews-above-average/?europe=true#1YLfzOC34sqd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_thresh = df_listings['review_scores_rating'].quantile([0.05, .1, .25, .5, .75, 0.9, 0.95]).values[0]\n",
    "bottom_listings = df_listings[df_listings[\"review_scores_rating\"]<=bottom_thresh].copy()\n",
    "#len(bottom_listings)\n",
    "\n",
    "for rev_col in [x for x in bottom_listings.columns.tolist() if x.startswith(\"review_scores\")]:\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    sns.distplot(df_listings[rev_col],kde = False, label=\"{}-overall\".format(rev_col))\n",
    "    sns.distplot(bottom_listings[rev_col],kde = False, label=\"{}-bottom 10\".format(rev_col))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the threshold scores for the bottom 5% according to each component, we see different thresholds. What this tells us is that even the lowest scoring listings tend to have relatively high scores for certain components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rev_col in [x for x in bottom_listings.columns.tolist() if x.startswith(\"review_scores\")]:\n",
    "    print(\"Median {}-overall: {:.2f}\".format(rev_col,df_listings[rev_col].median()), \"Median {}-bottom 5%: {:.2f}\".format(rev_col,bottom_listings[rev_col].median()),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let's look at listings which score a 7 or below for each component score and see what kind of comments are submitted vs the general population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generate_wordcloud(this_df,title):\n",
    "    \n",
    "    this_merged_df = pd.merge(this_df,\n",
    "                  df_reviews_details,\n",
    "                  left_on='id',\n",
    "                  right_on='listing_id',\n",
    "                  how='left')\n",
    "    this_merged_df.comments.fillna('', inplace=True)\n",
    "\n",
    "    # https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d\n",
    "    this_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "    these_comments = this_merged_df.comments.tolist()\n",
    "    X = this_vectorizer.fit_transform(these_comments) #get cleaned text and word counts in each comment, returns an array\n",
    "    total_counts = X.sum(axis=0) #sum counts by word (word is a column in matrix)\n",
    "    count_by_word = [(word, total_counts[0, idx]) for word, idx in this_vectorizer.vocabulary_.items()] #get counts by word in an array of word, count pairs\n",
    "\n",
    "    df_count_by_word = sorted(count_by_word, key = lambda x: x[1], reverse=True)\n",
    "    df_count_by_word = pd.DataFrame.from_records(df_count_by_word,columns=['Words','Frequency']).sort_values([\"Frequency\"],ascending=False)\n",
    "\n",
    "    # https://stackoverflow.com/questions/43043437/wordcloud-python-with-generate-from-frequencies\n",
    "    dict_count_by_word = dict(zip(df_count_by_word.Words,df_count_by_word.Frequency))\n",
    "    # Relative scaling value is to adjust the importance of a frequency word.\n",
    "    wordcloud = WordCloud(width=900,height=500, max_words=1628,relative_scaling=1,normalize_plurals=False).generate_from_frequencies(dict_count_by_word)\n",
    "    print(\"Wordcloud - {}\".format(title))\n",
    "    plt.figure( figsize=(20,10) )\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_generate_wordcloud(df_listings,\"overall listings\")\n",
    "\n",
    "for rev_col in [x for x in bottom_listings.columns.tolist() if x.startswith(\"review_scores\")]:\n",
    "    if rev_col != \"review_scores_rating\":\n",
    "        bottom_listings = df_listings[df_listings[rev_col]<=7].copy()\n",
    "        my_generate_wordcloud(bottom_listings,\"score <=7 in {}\".format(rev_col))\n",
    "        \n",
    "        \n",
    "del bottom_listings, df_reviews_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't quite spot anything amiss. Looks like generally all listings on AirBnB score highly. Whether this is true or artificial, I leave that to you to ponder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.XX What is the availability of listings over time?\n",
    "\n",
    "From the graph below, we can see the following:\n",
    "\n",
    "1. Availability appears to increase up to around Christmas before hitting a low on New Year's Eve. This indicates high bookings during festive seasons.\n",
    "2. Availability again drops in early Feb, could this be during uni term holidays?\n",
    "3. Further into the future, availability is generally lower.\n",
    "\n",
    "Note however, availability is marked as false if a. the property is booked, or b. the owner has not marked it as available for some reason. Therefore, reason 3. above can likely be explained by owners not thinking too far into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = pd.merge(df_calendar,\n",
    "                       df_listings[['id','neighbourhood']],\n",
    "                       left_on='listing_id',\n",
    "                       right_on='id',\n",
    "                       how='left')\n",
    "\n",
    "\n",
    "df_calendar.drop(\"id\",inplace=True,axis=1)\n",
    "\n",
    "# https://stackoverflow.com/a/35415751\n",
    "df_grouped = df_calendar.groupby([\"date\",\"neighbourhood\",\"available\"])[\"listing_id\"].count().unstack('available')\n",
    "\n",
    "df_grouped.fillna(0,inplace=True)\n",
    "df_grouped = df_grouped.apply(lambda r: r/r.sum(),axis=1)\n",
    "df_grouped = df_grouped.reset_index()\n",
    "df_grouped.drop(\"f\",axis=1,inplace=True)\n",
    "\n",
    "fig = px.line(df_grouped, x=\"date\", y=\"t\", color='neighbourhood')\n",
    "fig.update_layout(title_text='Availability over time by neighbourhood')\n",
    "fig.update_xaxes(title_text='Date')\n",
    "fig.update_yaxes(title_text='% Availability',range=[0, 1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.XX How does price behave over time?\n",
    "\n",
    "We see the following:\n",
    "\n",
    "1. Prices are high on new year's eve\n",
    "2. prices are high during summer months\n",
    "3. Westminster, Camden, Kensington, City of London consistently price higher than other boroughs. This makes sense! Central London!\n",
    "4. For some odd reason, prices shoot up in Nov 2020!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calendar = pd.merge(df_calendar,\n",
    "                       df_listings[['id','room_type']],\n",
    "                       left_on='listing_id',\n",
    "                       right_on='id',\n",
    "                       how='left')\n",
    "\n",
    "\n",
    "#df_calendar[\"price\"] = df_calendar[\"price\"].str.replace(\",\",\"\")\n",
    "#df_calendar[\"price\"] = df_calendar[\"price\"].str.replace(\"$\",\"\")\n",
    "#df_calendar[\"price\"] = df_calendar[\"price\"].astype(float)\n",
    "\n",
    "df_grouped = df_calendar.groupby([\"room_type\",\"date\",\"neighbourhood\"])[\"price\"].median()\n",
    "df_grouped.fillna(0,inplace=True)\n",
    "df_grouped = df_grouped.unstack(\"room_type\")\n",
    "df_grouped = df_grouped.reset_index()\n",
    "\n",
    "for this_room in list(df_listings.room_type.unique()):\n",
    "    fig = px.line(df_grouped, x=\"date\", y=this_room, color='neighbourhood')\n",
    "    fig.update_layout(title_text='Median price over time by neighbourhood - {}'.format(this_room))\n",
    "    fig.update_xaxes(title_text='Date')\n",
    "    fig.update_yaxes(title_text='Price')#,range=[df_grouped[df_listings.room_type.unique()].min().min(), df_grouped[df_listings.room_type.unique()].max().max()])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
